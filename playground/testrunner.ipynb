{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20686b05-5143-4866-b100-0aad14638da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEnergy captured: ranks needed\\n 5%: 14  10%: 29  15%: 46  20%: 64   25%:  84\\n30%: 106 35%: 129 40%: 154 45%: 182  50%:  215\\n55%: 252 60%: 297 65%: 354 70%: 443  75%:  552\\n80%: 670 85%: 798 90%: 935 95%: 1084 100%: 1250 \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.linalg import qr\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pywt\n",
    "#from random import randint\n",
    "\n",
    "BAD = ['VT', 'VFb', 'VFt'] # KIS,S\n",
    "project_dir = r'C:\\Users\\jodge\\Documents\\School\\Summer24\\tinymlcontest2022_demo_example'\n",
    "dir_path = r'C:\\Users\\jodge\\Documents\\School\\Summer24\\tinyml_contest_data_training'\n",
    "directory_files = os.listdir(dir_path)\n",
    "\n",
    "training_script = os.path.join(project_dir, 'training_save_deep_models.py')\n",
    "testing_script = os.path.join(project_dir, 'testing_performances.py')\n",
    "models_dir = os.path.join(project_dir, 'models')\n",
    "results_dir = os.path.join(project_dir, 'results')\n",
    "\n",
    "\"\"\"\n",
    "Energy captured: ranks needed\n",
    " 5%: 14  10%: 29  15%: 46  20%: 64   25%:  84\n",
    "30%: 106 35%: 129 40%: 154 45%: 182  50%:  215\n",
    "55%: 252 60%: 297 65%: 354 70%: 443  75%:  552\n",
    "80%: 670 85%: 798 90%: 935 95%: 1084 100%: 1250 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a175f14c-5c67-4562-bf3d-2ef8b2dd48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readObj(filename):\n",
    "    print(f\"reading from {filename}\")\n",
    "    with open(filename, 'rb') as file:\n",
    "       return pickle.load(file)\n",
    "def saveObj(obj, filename):\n",
    "    print(f\"saving to {filename}\")\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(obj, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17057abe-416b-4422-aaf4-11b088c4ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCorrectModel(path, wanted = \"original\"):\n",
    "    if wanted == \"original\":\n",
    "        #os.rename(os.path.join(path, 'model_1.py.og'), os.path.join(path,'model_1.py'))\n",
    "        return f\"ren {os.path.join(path, 'model_1.py.og')} model_1.py\"\n",
    "    elif wanted == \"avgpool\":\n",
    "        #os.rename(os.path.join(path, 'model_1.py.avgpool'), os.path.join(path,'model_1.py'))\n",
    "        return f\"ren {os.path.join(path, 'model_1.py.avgpool')} model_1.py\"\n",
    "        \n",
    "def resetModel(models_dir, used = \"original\"):\n",
    "    if used == \"original\":\n",
    "        #os.rename(models_dir, os.path.join(models_dir, 'model_1.py.og'))\n",
    "        return f\"ren {os.path.join(models_dir, 'model_1.py')} model_1.py.og\"\n",
    "    elif used == \"avgpool\":\n",
    "        #os.rename(models_dir, os.path.join(models_dir,'model_1.py.avgpool'))\n",
    "        return f\"ren {os.path.join(models_dir, 'model_1.py')} model_1.py.avgpool\"\n",
    "    else:\n",
    "        print(\"BAD!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff8d2c46-ea43-4764-a39a-4a778ea2eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(): #for SVD\n",
    "    problemSetupsDir = r'C:\\Users\\jodge\\Documents\\School\\Summer24\\playground\\data'\n",
    "    problemSetup = readObj(os.path.join(problemSetupsDir, 'full.pkl'))\n",
    "    print(problemSetup.r, problemSetup.p) # make sure it's working\n",
    "        \n",
    "    for fi in tqdm(directory_files): #special iterator that makes a progress bar\n",
    "        temp = np.loadtxt(os.path.join(dir_path,fi))\n",
    "        mse, recon = measureAndReconstruct(problemSetup, temp)\n",
    "        trunc = problemSetup.C @ temp\n",
    "        \n",
    "        outReconName = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24\\recon_data', 'R' + fi) \n",
    "        outTruncName = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24\\trunc_data', 'T' + fi)\n",
    "        np.savetxt(outReconName, recon, fmt='%.7f')\n",
    "        np.savetxt(outTruncName, trunc, fmt='%.7f')\n",
    "    \n",
    "    print(\"DONE\")\n",
    "    return r, p # ive been using p (which should be r+1) for file naming. idk why i chose that convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "698471c4-3b0b-4d48-9267-6658a07727e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from data\\fullTrainMat.pkl\n"
     ]
    }
   ],
   "source": [
    "class SVD:\n",
    "    def __init__(self, U, S, VT):\n",
    "        self.U = U\n",
    "        self.S = S\n",
    "        self.VT = VT\n",
    "\n",
    "class ProblemSetup:\n",
    "  def __init__(self, r, p, fullSVD, truncSVD, Q, R, pivots, C):\n",
    "      self.r = r # ranks to use\n",
    "      self.p = p # number of sensors\n",
    "      self.fullSVD = fullSVD\n",
    "      self.truncSVD = truncSVD\n",
    "      self.Q = Q\n",
    "      self.R = R\n",
    "      self.pivots = pivots\n",
    "      self.C = C\n",
    "      \n",
    "def getFullTrainSignalMatrix(): #all files with each as a column\n",
    "    pkl_name = r\"fullTrainMat.pkl\"\n",
    "    pkl_loc = os.path.join(\"data\", pkl_name)\n",
    "\n",
    "    if os.path.exists(pkl_loc):\n",
    "        answer = readObj(pkl_loc)\n",
    "        return answer\n",
    "    else:\n",
    "        print(f\"{pkl_loc} not found - see other notebooks for generation\")\n",
    "        \n",
    "def processData(trainingData, label, r = 400, p = 500): # r = ranks desired, p = num sensors. bug when r=p, math is hard.\n",
    "    U, S, VT = svd(trainingData)\n",
    "    full_SVD = SVD(U, S, VT)\n",
    "    \n",
    "    #reshape SVD according to r\n",
    "    U_hat, S_hat, VT_hat = U[:,:r], S[:r,:r], VT[:r,:]\n",
    "    trunc_SVD = SVD(U_hat, S_hat, VT_hat)\n",
    "    \n",
    "    Q, R, pivots = None, None, None\n",
    "    if (p == r):\n",
    "        Q, R, pivots = qr(U_hat, pivoting = True) # or maybe just U\n",
    "    elif (p > r): # oversampled\n",
    "        Q, R, pivots = qr(U_hat @ U_hat.T, pivoting = True) # or maybe just U\n",
    "    else:\n",
    "        for _ in range(100):\n",
    "            print(\"ERROR p < r\")\n",
    "            \n",
    "    pivots = pivots[:p]\n",
    "    \n",
    "    # Create C matrix\n",
    "    C = np.zeros((p, getFullTrainSignalMatrix().shape[0]))\n",
    "    #print(C.shape, pivots.shape)\n",
    "    C[np.arange(p), pivots] = 1\n",
    "\n",
    "    problemSetup = ProblemSetup(r, p, full_SVD, trunc_SVD, Q, R, pivots, C)\n",
    "    filename = os.path.join(\"data\", label + \".pkl\")\n",
    "    saveObj(problemSetup, filename)\n",
    "    \n",
    "    return problemSetup\n",
    "    \n",
    "def svd(x = getFullTrainSignalMatrix()):\n",
    "    U, S, VT = np.linalg.svd(x, full_matrices=True) #full_matrices=False\n",
    "    S = np.diag(S)\n",
    "    return (U, S, VT)\n",
    "\n",
    "def measureAndReconstruct(problemSetup, signal):\n",
    "    # Measure a signal\n",
    "    C, U_hat, p, r, pivots =  problemSetup.C, problemSetup.truncSVD.U, problemSetup.p, problemSetup.r, problemSetup.pivots\n",
    "    y = C @ signal\n",
    "    \n",
    "    # Solve for coefficients\n",
    "    U_k_reduced = U_hat[:, :p][pivots, :]\n",
    "    \n",
    "    if p == r: # broken, bad shapes\n",
    "        a = np.linalg.lstsq(U_k_reduced, y, rcond=None)[0]\n",
    "    else:\n",
    "        a = np.linalg.pinv(C @ U_hat) @ y\n",
    "\n",
    "    x_reconstructed = U_hat @ a\n",
    "    mseFinal = np.mean((signal - x_reconstructed) ** 2)\n",
    "    return mseFinal, x_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fdaff00-25b3-47a5-acc6-1868220c439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batGen(rp, numRuns=5, mode = \"normal\", sampleRate = 1.0, length = 1250, model = \"original\", kept = 100):\n",
    "    ans = []\n",
    "\n",
    "    recon_indices_dir = os.path.join(project_dir, 'recon_indices\\\\')\n",
    "    trunc_indices_dir = os.path.join(project_dir, 'trunc_indices\\\\')\n",
    "    drop_indices_dir = os.path.join(project_dir, 'drop_indices\\\\')\n",
    "    fft_indices_dir = os.path.join(project_dir, 'fft_indices\\\\')\n",
    "    \n",
    "    data_dir = r'C:\\Users\\jodge\\Documents\\School\\Summer24'\n",
    "    recon_data_dir = os.path.join(data_dir, 'recon_data\\\\')\n",
    "    trunc_data_dir = os.path.join(data_dir, 'trunc_data\\\\')\n",
    "    drop_data_dir = os.path.join(data_dir, 'drop_data\\\\')\n",
    "    fft_data_dir = os.path.join(data_dir, 'fft_data\\\\')\n",
    "\n",
    "    path_flags = ''\n",
    "    if mode == 'recon':\n",
    "        path_flags = f'--path_data {recon_data_dir} --path_indices {recon_indices_dir}'\n",
    "    elif mode == 'trunc':\n",
    "        path_flags = f'--path_data {trunc_data_dir} --path_indices {trunc_indices_dir}'\n",
    "    elif mode == 'drop' or mode == 'random':\n",
    "        path_flags = f'--path_data {drop_data_dir} --path_indices {drop_indices_dir}'\n",
    "    elif mode == 'fft':\n",
    "        path_flags = f'--path_data {fft_data_dir} --path_indices {fft_indices_dir}'\n",
    "        \n",
    "\n",
    "    size_flags = ''\n",
    "    if length < 98:\n",
    "        length = 98\n",
    "    if length != 1250:\n",
    "        if model == 'avgpool':\n",
    "            size_flags = f'--size {length}'\n",
    "\n",
    "    sample_flags = f'--sample_rate {sampleRate}' if sampleRate != 1.0 else ''\n",
    "    sample_flags_temp = f'_{int(sampleRate)}' if sample_flags else ''\n",
    "    sample_flags_temp.replace('.','-')\n",
    "    \n",
    "    temp_kept_flag = '_k'+str(kept) if kept != 100 else ''\n",
    "    print(sample_flags_temp, temp_kept_flag)\n",
    "\n",
    "    out_train_name = f'train_{mode}_r{rp}_{length}{sample_flags_temp}_{model}.txt'\n",
    "    out_test_name = f'TEST_{mode}_r{rp}_{length}{sample_flags_temp}{temp_kept_flag}_{model}.csv'\n",
    "    output_train_file = os.path.join(results_dir, out_train_name)\n",
    "    output_test_file = os.path.join(results_dir, out_test_name)\n",
    "\n",
    "    temp_train_out = 'train_temp.txt'\n",
    "    temp_test_out = 'test_temp.txt'\n",
    "    train_command = f'\\tpython {training_script} {path_flags} {sample_flags} {size_flags} >> {output_train_file}'\n",
    "    test_command = f'\\tpython {testing_script} {path_flags} {sample_flags} {size_flags} >> {output_test_file}'\n",
    "\n",
    "    loop_head = r'for /l %%i in (1,1,' + str(numRuns) + r') do ('\n",
    "    loop_tail = ')'\n",
    "\n",
    "    ans.append(r'@echo off')\n",
    "    ans.append(setCorrectModel(models_dir, model))  \n",
    "    ans.append(loop_head)\n",
    "    \n",
    "    ans.append('\\techo iteration %%i')\n",
    "    ans.append(train_command)\n",
    "    ans.append(test_command)\n",
    "    \n",
    "    ans.append(loop_tail)\n",
    "    ans.append(resetModel(models_dir, model))\n",
    "    ans.append('pause')\n",
    "    \n",
    "    bat_name = out_test_name.split(\".\")[0]\n",
    "    bat_name = \"_\".join(bat_name.split(\"_\")[1:]) + \".bat\"\n",
    "\n",
    "    bat = os.path.join(\"bats\", bat_name)\n",
    "    with open(bat,\"w\") as output:\n",
    "        for line in ans:\n",
    "            output.write(line + '\\n')\n",
    "    \n",
    "    return ans, bat_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be627996-e49c-404c-b91f-87f87f665248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batGenNew(out_train_name, out_test_name, numRuns = 5, indices_folder = None, data_folder=None, length=1250, model = 'original', additional_flags = ''):\n",
    "    ans = []\n",
    "\n",
    "    output_train_file = os.path.join(results_dir, out_train_name)\n",
    "    output_test_file = os.path.join(results_dir, out_test_name)\n",
    "\n",
    "    path_flags = ''\n",
    "    if data_folder:\n",
    "        data_path = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24', data_folder)\n",
    "        path_flags = path_flags + f' --path_data {data_path}'\n",
    "    if indices_folder:\n",
    "        indices_path = os.path.join(project_dir, indices_folder)\n",
    "        path_flags = path_flags + f' --path_indices {indices_path}'\n",
    "    #path_flags = f'--path_data {data_path} --path_indices {indices_path}' if indices_folder or data_folder else ''\n",
    "\n",
    "    size_flags = ''\n",
    "    if length < 98:\n",
    "        length = 98\n",
    "    if length != 1250 and model == 'avgpool':\n",
    "        size_flags = f'--size {length}'\n",
    "\n",
    "    train_command = f'\\tpython {training_script} {path_flags} {size_flags} {additional_flags} >> {output_train_file}'\n",
    "    test_command = f'\\tpython {testing_script} {path_flags} {size_flags} {additional_flags} >> {output_test_file}'\n",
    "\n",
    "    loop_head = r'for /l %%i in (1,1,' + str(numRuns) + r') do ('\n",
    "    loop_tail = ')'\n",
    "\n",
    "    ans.append(r'@echo off')\n",
    "    ans.append(setCorrectModel(models_dir, model))  \n",
    "    ans.append(loop_head)\n",
    "    \n",
    "    ans.append('\\techo iteration %%i')\n",
    "    ans.append(train_command)\n",
    "    ans.append(test_command)\n",
    "    \n",
    "    ans.append(loop_tail)\n",
    "    ans.append(resetModel(models_dir, model))\n",
    "    ans.append('pause')\n",
    "    \n",
    "    bat_name = out_test_name.split(\".\")[0]\n",
    "    bat_name = \"_\".join(bat_name.split(\"_\")[1:]) + \".bat\"\n",
    "\n",
    "    bat = os.path.join(\"bats\", bat_name)\n",
    "    with open(bat,\"w\") as output:\n",
    "        for line in ans:\n",
    "            output.write(line + '\\n')\n",
    "    \n",
    "    return bat_name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecfabb6-7ac0-4f7b-9ae3-8c464db12087",
   "metadata": {},
   "source": [
    "# CHOOSE WHAT TO RUN FROM HERE!\n",
    "### Set your variables and then move the .bat to the right folder and then run it from CMD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d0b87-d705-4409-88cf-72749916a507",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3762f06b-3829-48a7-bdc3-bdd9fc7f5821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from data\\fullTrainMat.pkl\n",
      "reading from data\\fullTrainMat.pkl\n",
      "saving to data\\full.pkl\n",
      "reading from C:\\Users\\jodge\\Documents\\School\\Summer24\\playground\\data\\full.pkl\n",
      "1250 1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 30213/30213 [3:32:06<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "1250 1250 1250 1250\n"
     ]
    }
   ],
   "source": [
    "r = 1250\n",
    "p = r#+1\n",
    "fullTrainSignalMatrix = getFullTrainSignalMatrix()\n",
    "problemSetup = processData(fullTrainSignalMatrix, \"full\", r, p)\n",
    "r0,p0 = prepareData()\n",
    "print(r,r0, p,p0) # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ef0acb8-b550-46d9-8bef-b71733dc373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "trunc_r1250_1250_avgpool.bat\n"
     ]
    }
   ],
   "source": [
    "ans, bat_name = batGen(p, mode = \"trunc\", sampleRate = 1.0, length = p, model=\"avgpool\")\n",
    "print(bat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a52c7-aa61-4c27-9e14-27da9f964ae5",
   "metadata": {},
   "source": [
    "# Random Dropout (Static Mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d703525-66b0-403e-af00-cef27b4f3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_drop_mask(keep_percentage, length=1250):\n",
    "    \"\"\" CLAUDE\n",
    "    Randomly drop data points from a NumPy array.\n",
    "    \n",
    "    :param data: Input NumPy array\n",
    "    :param keep_percentage: Percentage of data points to keep (0-100)\n",
    "    :return: Filtered NumPy array with the desired percentage of data points\n",
    "    \"\"\"\n",
    "    if not 0 < keep_percentage <= 100:\n",
    "        raise ValueError(\"Keep percentage must be between 0 and 100\")\n",
    "    \n",
    "    # Generate a binary mask with the desired probability of keeping each element\n",
    "    keep_mask = np.random.binomial(1, keep_percentage / 100, size=length).astype(bool)\n",
    "    \n",
    "    # Apply the mask to the original data\n",
    "    #filtered_data = data[keep_mask]\n",
    "    \n",
    "    return keep_mask\n",
    "    \n",
    "def randomDropout(keep_percent = 50, trunc = True):\n",
    "    mask = random_drop_mask(keep_percent)\n",
    "    print(f\"keep: {keep_percent}%. mask: {np.sum(mask)}\") \n",
    "\n",
    "    for fi in tqdm(directory_files, desc=\"Static Random Mask\"): #special iterator that makes a progress bar\n",
    "        temp = np.loadtxt(os.path.join(dir_path,fi))\n",
    "        dropped = None\n",
    "        if trunc:\n",
    "            dropped = temp[mask]\n",
    "        else:\n",
    "            dropped = np.where(mask, temp, 0)\n",
    "        \n",
    "        outName = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24\\drop_data', 'D' + fi)\n",
    "        np.savetxt(outName, dropped, fmt='%.7f')\n",
    "    \n",
    "    print(\"DONE\")\n",
    "    return np.sum(mask) # how many data points were kept (should be close to 1250 * keep percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7214ea36-467f-4379-9e32-017e7b83ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "keeping = 8.56 #kep 50%\n",
    "trunc = False\n",
    "mod = \"original\"\n",
    "if mod == \"original\":\n",
    "    trunc = False\n",
    "masklen = randomDropout(keeping, trunc)\n",
    "length = masklen if trunc else 1250    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c0b7c-c106-45fa-9f78-7b332417efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keeping = str(keeping).replace('.','-')  \n",
    "ans, bat_name = batGen(masklen, mode = \"drop\", length = length, model = \"original\", kept = keeping)\n",
    "print(bat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5208967-a2ab-4302-9f30-fd54c5b00a09",
   "metadata": {},
   "source": [
    "# Random Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d033a-255c-417d-8430-154f2f5c9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_percentage = 50\n",
    "longest = 0\n",
    "model = 'original'\n",
    "trunc = True\n",
    "if model == 'original':\n",
    "    trunc = False\n",
    "\n",
    "for fi in tqdm(directory_files[:], desc=f\"Totally Random {keep_percentage}%\"): #special iterator that makes a progress bar\n",
    "    temp = np.loadtxt(os.path.join(dir_path,fi))\n",
    "    temp_mask = np.random.binomial(1, keep_percentage / 100, size=1250).astype(bool)\n",
    "    temp_len = np.sum(temp_mask)\n",
    "    longest = temp_len if temp_len > longest else longest\n",
    "    \n",
    "    if trunc:\n",
    "        dropped = temp[temp_mask]\n",
    "    else:\n",
    "        dropped = np.where(temp_mask, temp, 0)\n",
    "        \n",
    "    outName = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24\\drop_data', fi)\n",
    "    np.savetxt(outName, dropped, fmt='%.7f')\n",
    "\n",
    "keep_percentage = str(keep_percentage).replace('.','-')\n",
    "out_train_name = f'train_rand_k{keep_percentage}_l{longest}_{model}.txt'\n",
    "out_test_name = f'TEST_rand_k{keep_percentage}_l{longest}_{model}.csv'\n",
    "data_folder = 'drop_data\\\\'\n",
    "bat_name = batGenNew(out_train_name, out_test_name, numRuns = 5, indices_folder = None, data_folder=data_folder, length=longest, model = 'avgpool')\n",
    "bat_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c961668f-5490-4d48-80c4-39d4e53b7fdc",
   "metadata": {},
   "source": [
    "# FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0eb5c470-2533-4407-be5e-6159e36b71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fftMask(ranks = 250):\n",
    "    pkl_name = \"fftMask\" + str(ranks) + \".pkl\"\n",
    "    pkl_loc = os.path.join(\"data\", pkl_name)\n",
    "    mask = None\n",
    "\n",
    "    if os.path.exists(pkl_loc):\n",
    "        mask = readObj(pkl_loc)\n",
    "    else:\n",
    "        temp = np.fft.rfft(np.loadtxt(os.path.join(dir_path,directory_files[0])))\n",
    "        counts = np.zeros_like(temp)\n",
    "        print()\n",
    "        for fi in tqdm(directory_files, desc = f\"Generating FFT mask of {ranks} ranks.\"):\n",
    "            temp = np.loadtxt(os.path.join(dir_path,fi))\n",
    "            fft = np.fft.rfft(temp)\n",
    "            \n",
    "            ranked = np.argsort(np.abs(fft))[::-1]\n",
    "            top_indices = ranked[:ranks]\n",
    "            counts[top_indices] += 1\n",
    "        #print(f\"counts {counts}\")\n",
    "        \n",
    "        plt.plot(counts)\n",
    "        plt.title(\"counts\")\n",
    "        plt.show()\n",
    "            \n",
    "        final_indices = np.argsort(counts)[-ranks:]\n",
    "        #print(f\"{len(final_indices)} final idxs: {final_indices}\")\n",
    "        mask = np.zeros_like(counts, dtype=bool)\n",
    "        mask[final_indices] = True\n",
    "        saveObj(mask, pkl_loc)\n",
    "        \n",
    "    print(f\"mask of len {len(mask)} ready\")\n",
    "    return mask\n",
    "\n",
    "def fftSparseGen(mask, ranks, trunc = False):\n",
    "    for fi in tqdm(directory_files, desc=\"Files Processing\"):\n",
    "        temp = np.loadtxt(os.path.join(dir_path,fi))\n",
    "        fft = np.fft.rfft(temp)\n",
    "\n",
    "        if trunc:\n",
    "            done = fft[:][mask]\n",
    "        else: # zeroes otherwise\n",
    "            done = np.where(mask, fft, 0) \n",
    "        #print(len(done))\n",
    "        \n",
    "        outName = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24\\fft_data', 'F' + fi)\n",
    "        np.savetxt(outName, done.real, fmt='%.7f')\n",
    "    \n",
    "    print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b251cfe9-dfdd-41d1-9293-dd2226ca755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files Processing: 100%|█████████████████████████████████████████████████████████| 30213/30213 [00:46<00:00, 642.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bandpass_mask = np.zeros(626, dtype=bool)\n",
    "pass_band_filter = list(range(15*5,55*5))\n",
    "bandpass_mask[pass_band_filter] = True\n",
    "\n",
    "ranks = len(pass_band_filter)\n",
    "truncate = True\n",
    "#fftSparseGen(fftMask(ranks), ranks, trunc = truncate)\n",
    "fftSparseGen(bandpass_mask, ranks, trunc = truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8645af9-969e-4588-879d-d6bc4176eaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "fft_r200_200_avgpool.bat\n"
     ]
    }
   ],
   "source": [
    "len_temp = ranks if truncate else 1250\n",
    "ans, bat_name = batGen(ranks, mode = \"fft\", length = len_temp, model = \"avgpool\")\n",
    "print(bat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d083e960-fe18-47f0-b47a-bc1d655f62bf",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e039a7ea-2947-4533-ac97-f0f81cbb1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicDWTProcess(w='db4', m='zero'):\n",
    "    data = np.loadtxt(os.path.join(dir_path,directory_files[1]))\n",
    "    cA, cD = pywt.dwt(data, wavelet=w, mode=m)\n",
    "    size = len(cA)\n",
    "    \n",
    "    for fi in tqdm(directory_files, desc=\"Files Processing\"):\n",
    "        data = np.loadtxt(os.path.join(dir_path,fi))\n",
    "        cA, cD = pywt.dwt(data, wavelet=w, mode=m)\n",
    "        outName = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24\\temp_data', fi)\n",
    "        np.savetxt(outName, cA, fmt='%.7f')\n",
    "    \n",
    "    return size #return length after processing\n",
    "    \n",
    "def waveletDecomp(w='db4', m='zero', l=5, r=3):\n",
    "    data = np.loadtxt(os.path.join(dir_path,directory_files[1]))\n",
    "    coeffs = pywt.wavedec(data, w, mode=m, level=l)\n",
    "    #print(coeffs[r])\n",
    "    size = len(coeffs[r])\n",
    "    \n",
    "    for fi in tqdm(directory_files, desc=f\"{w} {m} {l}\"):\n",
    "        data = np.loadtxt(os.path.join(dir_path,fi))\n",
    "        coeffs = pywt.wavedec(data, w, mode=m, level=l)\n",
    "        outName = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24\\temp_data', fi)\n",
    "        np.savetxt(outName, coeffs[r], fmt='%.7f')\n",
    "    \n",
    "    return size #return length after processing  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939f4c5-fa12-4bb3-97e0-74033aa850b1",
   "metadata": {},
   "source": [
    "### simple DWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c6328c5-a7e3-4b07-aaa1-bc0cdb44c3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files Processing: 100%|█████████████████████████████████████████████████████████| 30213/30213 [01:13<00:00, 408.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dwt_db12_zero_r636_l636_avgpool.bat'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'db12'\n",
    "m = 'zero'\n",
    "length = basicDWTProcess(w,m)\n",
    "\n",
    "mod = 'avgpool'\n",
    "out_train_name = f'train_dwt_{w}_{m}_r{length}_l{length}_{mod}.txt'\n",
    "out_test_name = f'TEST_dwt_{w}_{m}_r{length}_l{length}_{mod}.csv'\n",
    "\n",
    "data_folder = \"temp_data\\\\\"\n",
    "\n",
    "bat_name = batGenNew(out_train_name, out_test_name, numRuns = 5, data_folder=data_folder, model = mod, length=length)\n",
    "bat_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab16b2-d574-4bd8-91f7-58eb472c2f10",
   "metadata": {},
   "source": [
    "### configurable wavelet decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456f8285-ee8b-491d-b451-4fe84e20a907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "coif3 zero 5: 100%|█████████████████████████████████████████████████████████████| 30213/30213 [03:18<00:00, 152.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'coif3_zero_5-3_r171-171_original.bat'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'coif3' # wavelet_list = ['db4', 'db6', 'db8', 'sym4', 'sym6', 'sym8', 'coif3', 'coif4', 'bior3.3', 'bior3.5']\n",
    "\n",
    "m = 'zero' # zero symmetric periodic\n",
    "levels = 5\n",
    "wanted = 3 #informed by waveletMaskCounter, seems to always be 3 at level 5 decomp\n",
    "length = waveletDecomp(w,m,l=levels,r=wanted)\n",
    "\n",
    "size = 98 if length < 98 else length\n",
    "\n",
    "mod = 'original'\n",
    "w = w.replace('.','-')\n",
    "file_setup = f'{w}_{m}_{levels}-{wanted}_r{length}-{size}_{mod}'\n",
    "out_train_name = f'train_{file_setup}.txt'\n",
    "out_test_name = f'TEST_{file_setup}.csv'\n",
    "\n",
    "data_folder = \"temp_data\\\\\"\n",
    "\n",
    "bat_name = batGenNew(out_train_name, out_test_name, numRuns = 10, data_folder=data_folder, model = mod, length=length)\n",
    "bat_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbdeac-5ca6-436e-b36d-de7a467b6621",
   "metadata": {},
   "source": [
    "# Short Time Length\n",
    "\n",
    "### note that on a model (avgpool) that accepts shorter than 1250 length inputs, you can just use the --size arg when running (hence \"trunc\" will be False by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1b47d75-9aad-489f-a686-629decbd3392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortenFiles(length, trunc = False):\n",
    "    \n",
    "    for fi in tqdm(directory_files, desc=f\"Shortening Data {length}/1250\"):\n",
    "        data = np.loadtxt(os.path.join(dir_path,fi))\n",
    "        data = data[:length]\n",
    "        outName = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24\\temp_data', fi)\n",
    "        np.savetxt(outName, data, fmt='%.7f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "399c4363-69eb-428a-ab89-1e73abc2c5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shortening Data: 100%|██████████████████████████████████████████████████████████| 30213/30213 [00:41<00:00, 727.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'short_107_1250_original.bat'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = 'original'\n",
    "points = 107\n",
    "\n",
    "#additional_flags = ''\n",
    "if mod == 'original':\n",
    "    length = 1250\n",
    "else:\n",
    "    length = points\n",
    "    #additional_flags = f'-- size {length}'\n",
    "\n",
    "shortenFiles(points, False)\n",
    "\n",
    "out_train_name = f'train_short_{points}_{length}_{mod}.txt'\n",
    "out_test_name = f'TEST_short_{points}_{length}_{mod}.csv'\n",
    "\n",
    "data_folder = \"temp_data\\\\\"\n",
    "\n",
    "bat_name = batGenNew(out_train_name, out_test_name, numRuns = 5, data_folder=data_folder, model = mod, length=length, additional_flags=additional_flags)\n",
    "bat_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651898d7-2c2e-4029-95e6-3e13e97902af",
   "metadata": {},
   "source": [
    "# Final Idea\n",
    "### Half Sample Rate, Half Length, DWT db4 zero cA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d3e49a2-60aa-4f3f-8f38-6ad0e074ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemblage(sample_rate = 2, length_percent = 625/1250, wavelet = 'db12', padding = 'zero'):\n",
    "    size = 0\n",
    "    for fi in tqdm(directory_files, desc=f\"Assemblage\"):\n",
    "        data = np.loadtxt(os.path.join(dir_path,fi))\n",
    "        n = len(data)\n",
    "        \n",
    "        data = data[:int(n * length_percent)]\n",
    "        data = data[::sample_rate]\n",
    "        cA, cD = pywt.dwt(data, wavelet=wavelet, mode=padding)\n",
    "        \n",
    "        size = len(cA)\n",
    "        outName = os.path.join(r'C:\\Users\\jodge\\Documents\\School\\Summer24\\temp_data', fi)\n",
    "        np.savetxt(outName, cA, fmt='%.7f')\n",
    "    \n",
    "    return size #return length after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ba93d9a-5812-4e0d-bf4a-e16e9712135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assemblage: 100%|███████████████████████████████████████████████████████████████| 30213/30213 [03:14<00:00, 155.25it/s]\n"
     ]
    }
   ],
   "source": [
    "mod = 'avgpool'\n",
    "\n",
    "sample_rate = 2\n",
    "length_percent = 625/1250\n",
    "wavelet='db4'\n",
    "padding='zero'\n",
    "epochs = 2\n",
    "\n",
    "length = assemblage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c2c643b-416b-490e-ad0a-bf2c3c16f969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assemblage_sr2_len50.bat'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if mod == 'original':\n",
    "    length = 1250\n",
    "\n",
    "out_train_name = f'train_assemblage_sr{sample_rate}_len{length_percent*100}_{wavelet}_{padding}_cA_fs{length}_{mod}.txt'\n",
    "out_test_name = f'TEST_assemblage_sr{sample_rate}_len{length_percent*100}_{wavelet}_{padding}_cA_fs{length}_{mod}.csv'\n",
    "\n",
    "data_folder = \"temp_data\\\\\"\n",
    "additional_flags = '' if epochs == 2 else f'--epoch {epochs}'\n",
    "\n",
    "bat_name = batGenNew(out_train_name, out_test_name, numRuns = 10, data_folder=data_folder, model = mod, length=length, additional_flags=additional_flags)\n",
    "bat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad030939-e5c6-4d8c-9a66-806a2a582260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
